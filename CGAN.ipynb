{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(30,12))\n",
    "n[:,-0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN(keras.Model):\n",
    "    \n",
    "    def __init__(self, input_dim, latent_dim, optimizer = None, conditional_dim=None):\n",
    "        super(CGAN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conditional_dim = conditional_dim\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.generator = self.create_generator()\n",
    "        self.discriminator = self.create_discrimenator()\n",
    "        \n",
    "        self.bc = tf.keras.losses.BinaryCrossentropy()\n",
    "        self.generator_optimizer = optimizer\n",
    "        self.discriminator_optimizer = optimizer\n",
    "        \n",
    "    def create_generator(self):\n",
    "         # generator of single events/cells\n",
    "        generator_input = keras.Input(shape=(self.latent_dim + self.conditional_dim,), name=\"generator_input\")\n",
    "        x = layers.Dense(10, activation=\"relu\", name=\"generator_l1\")(generator_input)\n",
    "        x = layers.Dense(8, activation=\"relu\",name=\"generator_l2\")(x)\n",
    "        x = layers.Dense(6, activation=\"relu\",name=\"generator_l3\")(x)\n",
    "        generator_output = layers.Dense(self.input_dim - self.conditional_dim, activation=\"relu\", name = \"generator_output\")(x)\n",
    "        return keras.Model(generator_input, generator_output, name=\"generator\")\n",
    "    \n",
    "    def create_discrimenator(self):\n",
    "        # generator of single events/cells\n",
    "        discriminator_input = keras.Input(shape=(self.input_dim,), name=\"discriminator_input\")\n",
    "        x = layers.Dense(10, activation=\"relu\", name=\"discriminator_l1\")(discriminator_input)\n",
    "        x = layers.Dense(8, activation=\"relu\",name=\"discriminator_l2\")(x)\n",
    "        x = layers.Dense(6, activation=\"relu\",name=\"discriminator_l3\")(x)\n",
    "        discriminator_output = layers.Dense(1, activation=\"sigmoid\", name = \"discriminator_output\")(x)\n",
    "        return keras.Model(discriminator_input, discriminator_output, name=\"discriminator\")\n",
    "    \n",
    "    \n",
    "    def generate_latent(self, shape):\n",
    "        # currently random noice, consider using a some distribution?\n",
    "        return np.random.normal(0,1, shape)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        return self.discriminator(inputs, training)\n",
    "    \n",
    "    def generator_loss(self,fake_output):\n",
    "        return self.bc(tf.ones_like(fake_output), fake_output)\n",
    "    \n",
    "    def discriminator_loss(self,real_output, fake_output):\n",
    "        real_loss = self.bc(tf.ones_like(fake_output), fake_output)\n",
    "        fake_loss = self.bc(tf.ones_like(fake_output), fake_output)\n",
    "        return real_loss + fake_loss\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0] # because data can be (x_batch, y_batch)\n",
    "        \n",
    "        noise = tf.random.normal([data.shape[0], self.latent_dim])\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            \n",
    "            if self.conditional_dim > 0:\n",
    "                \n",
    "                condition = data[:, -self.conditional_dim:]\n",
    "            \n",
    "                conditional_noise = keras.layers.concatenate([noise, condition], axis=1)\n",
    "            \n",
    "                generated_data_ = self.generator(conditional_noise, training=True)\n",
    "            \n",
    "                generated_data = keras.layers.concatenate([generated_data_, condition], axis=1)\n",
    "            \n",
    "            else:\n",
    "                generated_data = self.generator(noise, training=True)\n",
    "                \n",
    "                \n",
    "            real_output = self.discriminator(data, training=True)\n",
    "            fake_output = self.discriminator(generated_data, training=True)\n",
    "            \n",
    "            gen_loss = self.generator_loss(fake_output)\n",
    "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "            self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "            self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "    \n",
    "        return {\n",
    "            \"generator_loss\": gen_loss,\n",
    "            \"discriminator_loss\": disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = pd.read_csv(\"ModifiedDATA/scaled_ra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id(df):\n",
    "    cond = pd.get_dummies(df[\"group\"]).astype(\"float32\")\n",
    "\n",
    "    data = df[df.columns.difference([\"id\",\"group\"])]\n",
    "    data = np.concatenate((data, cond), axis=1)\n",
    "    \n",
    "    return cond, data\n",
    "\n",
    "cond, data = add_id(cells)\n",
    "cond_shape = cond.shape[1]\n",
    "data_shape = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 6s 1ms/step - generator_loss: 0.0021 - discriminator_loss: 0.0041 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x151b19fd0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECTED HYPERPARAMETERS\n",
    "LEARNING_RATE = 0.01\n",
    "OPTIMIZER = keras.optimizers.Adam(LEARNING_RATE)\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "LATENT_DIM = 2 \n",
    "\n",
    "d = cells[cells.columns.difference([\"id\",\"group\"])]\n",
    "\n",
    "model = CGAN(d.shape[1], LATENT_DIM, optimizer=OPTIMIZER, conditional_dim = 0)\n",
    "#model.build((None,input_shape))\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.fit(d, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_MODEL():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def convert_group(self, df):\n",
    "        cond = pd.get_dummies(df[\"group\"]).astype(\"float32\")\n",
    "\n",
    "        data = df[df.columns.difference([\"id\",\"group\"])]\n",
    "        data = np.concatenate((data, cond), axis=1)\n",
    "\n",
    "        return cond, data\n",
    "    \n",
    "    def fit(self, data, latent_dim, epochs, batch_size, optimizer):\n",
    "\n",
    "        # initilize the CVAE model\n",
    "        cond, data = self.convert_group(data)\n",
    "        cond_shape = cond.shape[1]\n",
    "        data_shape = data.shape[1]\n",
    "\n",
    "        self.model = CGAN(latent_dim = latent_dim, input_dim = data_shape, optimizer=optimizer, conditional_dim = cond_shape)\n",
    "\n",
    "        # compile the model\n",
    "        self.model.compile(optimizer=optimizer)\n",
    "        \n",
    "        # fit the model\n",
    "        self.model.fit(data, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        # save the model\n",
    "        self.model.save(filepath)\n",
    "    \n",
    "    def load(self, filepath):\n",
    "        # load the model\n",
    "        # set self.model\n",
    "        \n",
    "        # TODO if filepath exists.\n",
    "        self.model = keras.models.load_model(filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def generate_patients(self, nr_markers, latent_dim, conditional_dim, nr_cells = 20000, nr_patients = 20, column_names=None, group=None): \n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        nr_markers : int\n",
    "        latent_dim : int\n",
    "        conditional_dim : int\n",
    "        nr_cells : int\n",
    "        nr_patients : int\n",
    "        column_names : Dataframe.columns\n",
    "        group : str\n",
    "            \"control\" or \"diseased\"\n",
    "        \n",
    "        RETURNS\n",
    "        -------\n",
    "        \n",
    "        patients : dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.model:\n",
    "            \n",
    "            patients = np.empty(shape=(nr_patients* nr_cells, nr_markers))\n",
    "            p_id = np.empty(shape=nr_patients*nr_cells, dtype=\"int32\")\n",
    "\n",
    "            if group == \"control\":\n",
    "                gr = np.concatenate((np.ones(shape=(nr_cells,1)),np.zeros(shape=(nr_cells,1))), axis=1)\n",
    "            else:\n",
    "                gr = np.concatenate((np.zeros(shape=(nr_cells,1)),np.ones(shape=(nr_cells,1))), axis=1)\n",
    "\n",
    "            for i in range(nr_patients):\n",
    "                # patient ids\n",
    "                p_id[nr_cells*i : nr_cells*(i+1)] = np.full(shape=(nr_cells), fill_value=i+1, dtype=\"int32\")\n",
    "\n",
    "                sample = np.random.normal(0,1, size = (nr_cells, latent_dim))\n",
    "                latent_vals = np.concatenate((sample, gr),axis=1)\n",
    "\n",
    "                # sampled patient cells\n",
    "                patients[nr_cells*i : nr_cells*(i+1)] = self.model.generator.predict(latent_vals)#[:,:-conditional_dim]\n",
    "\n",
    "            patients_df = pd.DataFrame(patients, columns=column_names)\n",
    "\n",
    "\n",
    "            patients_df[\"id\"] = p_id\n",
    "            patients_df[\"group\"] = group\n",
    "\n",
    "            return patients_df\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmod = GAN_MODEL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 7s 1ms/step - generator_loss: 3.0977e-04 - discriminator_loss: 6.1954e-04 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "gmod.fit(cells,LATENT_DIM, EPOCHS, BATCH_SIZE, OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"GenerativeModels/CGAN_1.tf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GenerativeModels/CGAN_1.tf/assets\n"
     ]
    }
   ],
   "source": [
    "gmod.save(filepath = \"GenerativeModels/CGAN_1.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmod.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['145Nd_CD4', '146Nd_CD8a', '147Sm_CD20', '148Nd_CD16', '151Eu_CD123',\n",
       "       '159Tb_CD11c', '160Gd_CD14', '169Tm_CD45RA', '170Er_CD3',\n",
       "       '174Yb_HLA-DR', '176Yb_CD56', '209Bi_CD61', 'id', 'group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>145Nd_CD4</th>\n",
       "      <th>146Nd_CD8a</th>\n",
       "      <th>147Sm_CD20</th>\n",
       "      <th>148Nd_CD16</th>\n",
       "      <th>151Eu_CD123</th>\n",
       "      <th>159Tb_CD11c</th>\n",
       "      <th>160Gd_CD14</th>\n",
       "      <th>169Tm_CD45RA</th>\n",
       "      <th>170Er_CD3</th>\n",
       "      <th>174Yb_HLA-DR</th>\n",
       "      <th>176Yb_CD56</th>\n",
       "      <th>209Bi_CD61</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>90.422554</td>\n",
       "      <td>53.260834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.585601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.233582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.866409</td>\n",
       "      <td>60.575691</td>\n",
       "      <td>112.037247</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>82.556984</td>\n",
       "      <td>48.503777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.078922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.835732</td>\n",
       "      <td>55.349056</td>\n",
       "      <td>102.013855</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>105.428802</td>\n",
       "      <td>62.352001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.391577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.665985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.396088</td>\n",
       "      <td>70.411209</td>\n",
       "      <td>130.778259</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.906738</td>\n",
       "      <td>41.352383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.022319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.347652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.980492</td>\n",
       "      <td>47.669392</td>\n",
       "      <td>87.064865</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>113.416939</td>\n",
       "      <td>66.260117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.835961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.892845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.490562</td>\n",
       "      <td>75.266983</td>\n",
       "      <td>137.063843</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>76.429535</td>\n",
       "      <td>44.484463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.228112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.511868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.483295</td>\n",
       "      <td>51.065639</td>\n",
       "      <td>92.701370</td>\n",
       "      <td>20</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>84.703880</td>\n",
       "      <td>49.787182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.078473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.415287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.498039</td>\n",
       "      <td>56.766674</td>\n",
       "      <td>104.681229</td>\n",
       "      <td>20</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.308121</td>\n",
       "      <td>39.504189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.347192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.885887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.328674</td>\n",
       "      <td>45.633835</td>\n",
       "      <td>82.056732</td>\n",
       "      <td>20</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.990768</td>\n",
       "      <td>39.948502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.489857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.817314</td>\n",
       "      <td>46.108990</td>\n",
       "      <td>83.078445</td>\n",
       "      <td>20</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.167023</td>\n",
       "      <td>40.102577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.822261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.937561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.891212</td>\n",
       "      <td>46.288586</td>\n",
       "      <td>83.623001</td>\n",
       "      <td>20</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        145Nd_CD4  146Nd_CD8a  147Sm_CD20  148Nd_CD16  151Eu_CD123  \\\n",
       "0             0.0   90.422554   53.260834         0.0     4.585601   \n",
       "1             0.0   82.556984   48.503777         0.0     3.966102   \n",
       "2             0.0  105.428802   62.352001         0.0     5.391577   \n",
       "3             0.0   70.906738   41.352383         0.0     3.022319   \n",
       "4             0.0  113.416939   66.260117         0.0     2.835961   \n",
       "...           ...         ...         ...         ...          ...   \n",
       "399995        0.0   76.429535   44.484463         0.0     2.228112   \n",
       "399996        0.0   84.703880   49.787182         0.0     4.078473   \n",
       "399997        0.0   68.308121   39.504189         0.0     1.347192   \n",
       "399998        0.0   68.990768   39.948502         0.0     1.527784   \n",
       "399999        0.0   69.167023   40.102577         0.0     1.822261   \n",
       "\n",
       "        159Tb_CD11c  160Gd_CD14  169Tm_CD45RA  170Er_CD3  174Yb_HLA-DR  \\\n",
       "0               0.0   56.233582           0.0        0.0     70.866409   \n",
       "1               0.0   51.078922           0.0        0.0     64.835732   \n",
       "2               0.0   65.665985           0.0        0.0     82.396088   \n",
       "3               0.0   43.347652           0.0        0.0     55.980492   \n",
       "4               0.0   66.892845           0.0        0.0     89.490562   \n",
       "...             ...         ...           ...        ...           ...   \n",
       "399995          0.0   45.511868           0.0        0.0     60.483295   \n",
       "399996          0.0   52.415287           0.0        0.0     66.498039   \n",
       "399997          0.0   39.885887           0.0        0.0     54.328674   \n",
       "399998          0.0   40.489857           0.0        0.0     54.817314   \n",
       "399999          0.0   40.937561           0.0        0.0     54.891212   \n",
       "\n",
       "        176Yb_CD56  209Bi_CD61  id    group  \n",
       "0        60.575691  112.037247   1  control  \n",
       "1        55.349056  102.013855   1  control  \n",
       "2        70.411209  130.778259   1  control  \n",
       "3        47.669392   87.064865   1  control  \n",
       "4        75.266983  137.063843   1  control  \n",
       "...            ...         ...  ..      ...  \n",
       "399995   51.065639   92.701370  20  control  \n",
       "399996   56.766674  104.681229  20  control  \n",
       "399997   45.633835   82.056732  20  control  \n",
       "399998   46.108990   83.078445  20  control  \n",
       "399999   46.288586   83.623001  20  control  \n",
       "\n",
       "[400000 rows x 14 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = cells.columns.difference([\"id\", \"group\"])\n",
    "gmod.generate_patients(12,LATENT_DIM,2, column_names = col_names, group=\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
