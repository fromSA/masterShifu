{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5.2 Compare generated and original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:  The double-date metric\n",
    "- generated control cells/patients should be more similar to original control cells/patients than original diseased cells/patients\n",
    "- generated diseased cells/patients should be more similar to original diseased cells/patients than original control data\n",
    "- The difference between generated control and diseased cells/patients should be as close as possible to the difference between original control and diseased cells/patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "1. Train a generator on each group seperatly on the original data.\n",
    "2. Embedd the orignal data of each group seperately -> take each patients seperatly \n",
    "3. Generate patients -> embedd each patient using the same embedding space as the patients respective group.\n",
    "4. Get the KL-divergence between each pair of patient.\n",
    "    1. the kl-divergence is measured on the meshgrid spanning the union of each pair of patient cells.\n",
    "    2. Get two kernel density estimators, each trained on their respectiv patients embedding. Then use KL-divergence to compare the the estimations over the meshgrid.\n",
    "5. Use the double-date metric too compare generators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critisim\n",
    "1. Factors that might affect the metric\n",
    "    1. The embedding algorthim. The properties of some algorithm used will transfer to the metric.\n",
    "    2. The way KL-divergence is used. The span of the meshgrid will vary.\n",
    "    3. The kernel density estimator. Different parameters might give different results.\n",
    "    4. The generators themselves will vary with hyperparameters. (These are the models we to validate.)\n",
    "    5. The number of generated patients might affect metric. \n",
    "    6. The double-date metric might not be a good metric itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Train a generator on each group seperatly on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generated data \n",
    "# or load some generator \n",
    "# or train a generator - do this in another file\n",
    "def load_generated_patients(file):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    file: csv of generated cells for different patients.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file) \n",
    "\n",
    "\n",
    "def load_generator(file):\n",
    "    pass # TODO\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    pass # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Embedd each group seperately -> take each patients seperatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNE\n",
    "from openTSNE.callbacks import ErrorLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_embedd(df, embedder=None):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df: dataframe with cells of patients\n",
    "    embedder: umap embedding with existing embedded space.\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    embedder: umap embedder with existing embedded space\n",
    "    \n",
    "    embedded: embedding of df using embedder\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    group_embedding = dict()\n",
    "    \n",
    "    if(not embedder):\n",
    "        embedder = umap.UMAP(n_components=2, n_neighbors=10, random_state=0)\n",
    "\n",
    "    groups = [\"control\", \"diseased\"]\n",
    "    for g in groups:\n",
    "        group = df[df.group == g]\n",
    "        group_cells = group[group.columns.difference([\"id\",\"group\"])]\n",
    "        group_embedding[g] = embedder.fit_transform(group_cells)\n",
    "    return up, group_embedding\n",
    "    \n",
    "    \n",
    "def tsne_embedd(df, embedder=None):  \n",
    "    \"\"\"\n",
    "    PARAMETRS\n",
    "    ---------\n",
    "    df: dataframe with cells of patients\n",
    "    embedder: OpenTSNE - TSNEEmbedding object\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    embedder: tsne embedder with existing embedded space\n",
    "    \n",
    "    embedded: embedding of df using embedder\n",
    "    \n",
    "    \"\"\"\n",
    "    group_embedding = dict()\n",
    "    groups = [\"control\", \"diseased\"]\n",
    "    if(not embedder):\n",
    "        embedder = TSNE(n_components=2, perplexity=30, \n",
    "                    learning_rate=20, n_iter=1000, \n",
    "                    random_state=0)\n",
    "        \n",
    "        for g in groups:\n",
    "            group = df[df.group == g]\n",
    "            group_cells = group[group.columns.difference([\"id\",\"group\"])]\n",
    "            group_embedding[g] = tsne.fit(group_cells.values)\n",
    "    else:\n",
    "        for g in groups:\n",
    "            group = df[df.group == g]\n",
    "            group_cells = group[group.columns.difference([\"id\",\"group\"])]\n",
    "            group_embedding[g] = embeddor.transform(group_cells.values)\n",
    "            \n",
    "        \n",
    "    return tsne, group_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get the KL-divergence between each pair of patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kl_between_pairs(original, generated):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    original: a dictionary containing the embedded control and patient of the original patients\n",
    "    \n",
    "    generated: a dictonary containing the embedded control and patient of the generated patients\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    pairwise_kl: a list of matrices. each matrix contains a kl between two groups.\n",
    "    \n",
    "    \"\"\"\n",
    "    def KL(a,b):\n",
    "        a = np.asarray(a, dtype=np.float)\n",
    "        b = np.asarray(b, dtype=np.float)\n",
    "        a = np.exp(np.where(a!= float('-inf'), a, 0))\n",
    "        b = np.exp(np.where(b!= float('-inf'), b, 0))\n",
    "\n",
    "        cond = np.logical_and(b != float('-inf'), a!= float('-inf'), b != 0)\n",
    "    \n",
    "        return np.sum(np.where(cond, a * np.log(a / b), 0))\n",
    "    \n",
    "    def meshgrid(min_value = -15,max_value=15):\n",
    "        grid_margins = [np.linspace(min_value, max_value, 120)] * 2\n",
    "        grid = np.stack(np.meshgrid(*grid_margins), -1).reshape(-1, len(grid_margins))\n",
    "        return grid\n",
    "\n",
    "    def KL_between_two_patients(p1, p2, symmetric=True):\n",
    "        max_1 = np.max(p1)\n",
    "        min_1 = np.min(p1)\n",
    "        max_2 = np.max(p2)\n",
    "        min_2 = np.min(p2)\n",
    "        X = meshgrid(min_value = np.min([min_1, min_2])-1, max_value = np.max([max_1,max_2])+1 )\n",
    "\n",
    "        P_k_density_estimator = KernelDensity(kernel = \"linear\", bandwidth=1).fit(p1)\n",
    "        P_sample_score = P_k_density_estimator.score_samples(X)\n",
    "\n",
    "        Q_k_density_estimator = KernelDensity(kernel = \"linear\", bandwidth=1).fit(p2)\n",
    "        Q_sample_score = Q_k_density_estimator.score_samples(X)\n",
    "        kl_score = 0\n",
    "\n",
    "        if(symmetric):\n",
    "            kl_score = KL(P_sample_score, Q_sample_score) + KL(Q_sample_score, P_sample_score)\n",
    "        else:\n",
    "            kl_score = KL(P_sample_score, Q_sample_score)\n",
    "\n",
    "        return kl_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Double-date matric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualization of the pairwise KL-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
