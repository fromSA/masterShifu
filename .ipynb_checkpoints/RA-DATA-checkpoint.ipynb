{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'OriginalDATA/FlowRepository_FR-FCM-Z24N_files'\n",
    "files = os.listdir(file_path)\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = [f for f in files if \"KTR\" in f]\n",
    "\n",
    "unstim_control = [f for f in controls if 'unstim' in f]\n",
    "stim_control = [f for f in controls if ' stim' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = [f for f in files if \"RA\" in f]\n",
    "\n",
    "unstim_ras = [f for f in ras if \"unstim\" in f]\n",
    "stim_ras = [f for f in ras if \" stim\" in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- get a list of the channels that I want with their channel number\n",
    "- from the pandas get this channels\n",
    "- name the channels appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "- Cannot find functional marker p-Erk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RA-data description\n",
    "\n",
    "Mass cytometry (CyTOF)\n",
    "1. panel of 12 phenotyping and 10 functional markers\n",
    "2. signaling in unstimulated and TNF-stimulated peripheral blood mononulear cells\n",
    "3. from 20 newly diagnosed, untreated RA patients\n",
    "4. 20 healthy donors.\n",
    "\n",
    "1. unstim = unstimulated with tumor necrosis factor (TNF) (TNF inhibitors effectively repress inflammatory activity in RA)\n",
    "2. stim = stimulated with TNF\n",
    "3. ungated = manual removal of events representing \n",
    "\n",
    "## The RA paper:\n",
    "The objective of this study was to identify markers in immune cell populations that distinguish RA patients from healthy donors with an emphasis on TNF signaling\n",
    "\n",
    "We employed mass cytometry (CyTOF) with a panel of 13 phenotyping and 10 functional markers to explore signaling in unstimulated and TNF-stimulated peripheral blood mononuclear cells from 20 newly diagnosed, untreated RA patients and 20 healthy donors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. intracellular functional markers\n",
    "2. surface phenotypic markers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem:\n",
    "- want to collect more cells for each patient\n",
    "    - don't know what file belongs to each patient\n",
    "    - don't know which of the data is preprosessed or not\n",
    "- want to use more markers <b style=\"color:green\"> DONE </b> \n",
    "    - don't know how to get the other markers \n",
    "    - don't know which markers are phenotypical and which are functional\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(file, markers, nr_events):\n",
    "    f = flowio.flowdata.FlowData(file)\n",
    "    marker_channels = dict()\n",
    "    for j in markers:\n",
    "        for k in f.channels.keys():\n",
    "            if (j in f.channels[k]['PnS']):\n",
    "                marker_channels[int(k)] = f.channels[k]['PnS']\n",
    "    \n",
    "    npy_data = np.reshape(f.events, (-1, f.channel_count))\n",
    "    subsample = random.sample(list(npy_data), nr_events)\n",
    "    df = pd.DataFrame(subsample)\n",
    "    df2 = df.rename(columns=marker_channels)\n",
    "    return df2[list(marker_channels.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose files\n",
    "# choose nr of cells per patient\n",
    "# concatenate all files into one df\n",
    "# save the file\n",
    "# write about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patients(group_files, nr_cells, file_path, markers, group_name, id_key):\n",
    "    all_df = None\n",
    "    for i, file in enumerate(group_files):\n",
    "        path = file_path + \"/\" + file\n",
    "        df = get_events(path, markers, nr_cells)\n",
    "        key = \"({}-[0-9]+)\".format(id_key)\n",
    "        df[\"id\"] = i #re.findall(key, file)[0]\n",
    "        if i == 0:\n",
    "            all_df = df\n",
    "        else:\n",
    "            all_df = all_df.append(df)\n",
    "    all_df[\"group\"]=group_name\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phenotyping for clustering : cell type\n",
    "\n",
    "functional for within clustering : what happens IN the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the paper\n",
    "phenotyping = ['CD20','CD3','CD4','CD8a','CD45RA', 'CD56', \n",
    "               'CD16', 'CD14', 'CD61', 'CD11c','CD123', 'HLA-DR', 'CD45']\n",
    "\n",
    "functional = ['Caspase3', 'CD86','p-p38','p-Erk','p-Akt','p-cJun','p-NFkB','IkBa','CD120a','CD120b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df):\n",
    "    df_sub = df[df.columns.difference([\"id\",\"group\"])]\n",
    "    raw_scaled_df = df_sub.transform(lambda x: np.arcsinh(x/5))\n",
    "    df_scaled = raw_scaled_df.copy()\n",
    "    df_scaled[\"id\"] = df.id\n",
    "    df_scaled[\"group\"] = df.group\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scale_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ModifiedDATA/scaled_ra2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- prepare the 40 patients with the same number of events, and find such maximum item. (unstim)\n",
    "    - phenotyping\n",
    "    - functional\n",
    "    - phenotyping and functional\n",
    "- prepare the 40 patients with the same number of events, and find such maximum item. (stim for later)\n",
    "    - phenotyping\n",
    "    - functional\n",
    "    - phenotyping and functional\n",
    "- scale the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the minimum nr of cells in all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_control = float(\"inf\")\n",
    "for file in controls:\n",
    "    f = flowio.flowdata.FlowData(file_path + \"/\" + file)\n",
    "    if f.event_count < minimum_control:\n",
    "        minimum_control = f.event_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_ras = float(\"inf\")\n",
    "for file in ras:\n",
    "    f = flowio.flowdata.FlowData(file_path + \"/\" + file)\n",
    "    if f.event_count < minimum_ras:\n",
    "        minimum_ras = f.event_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159736"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_cells = 20000\n",
    "nr_cells = min(minimum_control, minimum_ras) # this gives 3194720 events per group, 6389440 in total for certain datatype.\n",
    "\n",
    "# max = 159736\n",
    "# n = 20 000, this might be too little.\n",
    "# n = 40 000\n",
    "# n = 50 000\n",
    "# n = 75 000 this the maximum we can get.\n",
    "data_shape = {\"ideal_ddloss\" : (n, n),\n",
    "              \"train + dd_test\": (n*0.8, n*0.2), \n",
    "              \"dimred_train + rest\": (n*0.2*0.8, n*0.8**2), \n",
    "              \"model testing\" : (n*0.8**2, n*0.8*0.2), \n",
    "              \"model validation\" : (n*0.8**3, n*0.8**2*0.2) # if k-fold is used, then this is not constant\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- possible issues with such large data set?\n",
    "    - need large models, takes longer to train\n",
    "    - takes time with dimensionality reduction\n",
    "- Advantage:\n",
    "    - can train better models, and avoid variance in the model\n",
    "- comparison:\n",
    "    - MNIST is 21 MB sized file\n",
    "    - Extended MNIST is 535 MB\n",
    "    - Kuzushiji MNIST is 31 MB\n",
    "    - BINARIZED MNIST is 104 MB\n",
    "- To try, nr_cells per patient\n",
    "    - 20 000\n",
    "    - 50 000\n",
    "    - 100 000\n",
    "    - 150 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cells = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = get_patients(unstim_control, nr_cells, file_path, phenotyping, \"control\", \"KTR\") \n",
    "df_rp = get_patients(unstim_ras, nr_cells, file_path, phenotyping, \"diseased\", \"RA\")\n",
    "\n",
    "df_cf = get_patients(unstim_control, nr_cells, file_path, functional, \"control\", \"KTR\")\n",
    "df_rf = get_patients(unstim_ras, nr_cells, file_path, functional, \"diseased\", \"RA\")\n",
    "\n",
    "df_cpf = get_patients(unstim_control, nr_cells, file_path, phenotyping + functional, \"control\", \"KTR\")\n",
    "df_crf = get_patients(unstim_ras, nr_cells, file_path, phenotyping + functional, \"diseased\", \"RA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df_cp.append(df_rp)\n",
    "df_f = df_cf.append(df_rf)\n",
    "df_pf = df_cpf.append(df_rpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = scale_df(df_p)\n",
    "df_f = scale_df(df_f)\n",
    "df_pf = scale_df(df_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"ModifiedDATA/scaled_ra_pheno_40000.csv\", index=False)\n",
    "df_f.to_csv(\"ModifiedDATA/scaled_ra_func_40000.csv\", index=False)\n",
    "df_pf.to_csv(\"ModifiedDATA/scaled_ra_phenofunc_40000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
