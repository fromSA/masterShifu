{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF399 \n",
    "\n",
    "A jupyter notebook containing all the code to reproduce your work and a report of all your methodological choices and results. Please \"restart and run all\" before submission, so that you submit a clean version. \n",
    "\n",
    "Code should be documented and special tricks (e.g. to avoid division by zero, to make sure it takes finite time to run, etc.) should be reported. The rational behind all steps in the code should be clear from the report. In particular, if you use are subsampling, you should report it, and you should consider for each step how much subsampling is appropriate. \n",
    "\n",
    "**NOTE:** \n",
    "Model selection is an important part of the task and will be graded accordingly. Before applying machine learning algorithms, you should always consider (and report) what results you expect. When you have successfully applied machine learning algorithms, you should always comment on how well the results match your expectations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Preprocessing \n",
    "In this task you summarize and visualize the data and prepare it for analysis. \n",
    "- Load data <b style=\"color:green\">DONE</b>\n",
    "- Decribe data <b style=\"color:green\">DONE</b>\n",
    "- Check for any missing values and handle these appropriately. <b style=\"color:green\">DONE</b>\n",
    "- Find the ranges and basic statistics of the features and rescale them if appropriate. For similar data, scaling using `arcsinh(x/5)` has been used successfully. <b style=\"color:green\">DONE</b>\n",
    "- Visualize the univariate densities of all features using your favorite density estimator. <b style=\"color:green\">DONE</b>\n",
    "- Calculate basic bivariate statistics, such as correlations. <b style=\"color:green\">DONE</b>\n",
    "- Perform any other appropriate preprocessing steps. <b style=\"color:green\">DONE</b>\n",
    "- Discuss the results of your summaries and visualization efforts and explain your preprocessing choices (not doing any preprocessing is also a choice). <b style=\"color:red\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T11:38:29.396417Z",
     "start_time": "2020-02-25T11:38:29.380077Z"
    }
   },
   "source": [
    "The datasets contain information on 20,000 blood cells of 20 rheumatoid arthritis patients and 20 healthy controls. The first two columns identify the patient and the patient group. The remaining columns are the cell markers measured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Dimensionality reduction\n",
    "\n",
    "- Visualize the mass cytometry dataset using at least three different representation learning algorithms.  <b style=\"color:orange\">HALF DONE</b>\n",
    "- Explain your choices of algorithms. <b style=\"color:red\">TODO</b>\n",
    "- For each algorithm, explain your choice of parameters. <b style=\"color:red\">TODO</b>\n",
    "- For each dimensionality reduction, describe the main features you see and discuss if these features come from the data or the dimensionality reduction technique. <b style=\"color:red\">TODO</b>\n",
    "- Discuss the differences and similarities of your dimensionality reductions. <b style=\"color:red\">TODO</b>\n",
    "- Embedd in 3D to get a possible better density estimation for each patient <b style=\"color:red\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - GMM\n",
    "- Use BIC and AIC to guess at number of componenets for the GMM model (model selection) <b style=\"color:green\">DONE</b>\n",
    "- Validate the result\n",
    "    - Train a dicriminator that tries to distinguish between generated and original data. Use that to rate the quality of generated data. I.E. GAN <b style=\"color:red\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Sample Patients\n",
    "- **Process:**\n",
    "    1. Embed the data in lower dim\n",
    "    2. Run kernel density estimation on the embedded sampled and original data\n",
    "    3. Look at the KL (symmetric) divergence on the estimated density between each pair of sampled and orignial patient using a grid space on the embedded space\n",
    "\n",
    "- **Notes:**\n",
    "    - Embedd in 3D to get a possible better density estimation for each patient <b style=\"color:red\">TODO</b>\n",
    "    - Draw the histogram of each axis on the umap-embedded patients to see why the sample generator does not produce evenly spaced samples. <b style=\"color:red\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "- include deep learning models and probabilistic models! \n",
    "\n",
    "validation:\n",
    "- use embedding to see if generated data and original data ends up similar (still donâ€™t know if correct, but if not similar then definately not similar) \n",
    "- Start with running inf367 project 2 with the new data, supsampling \n",
    "- Set up pipeline \n",
    "- Start with fitting GMM \n",
    "\n",
    "\n",
    "- We have a basic form of model selection for the GMM\n",
    "- We want to compare how good the new sampling is by\n",
    "    - Comparing a classifier trained on non-augmented data vs augmented data\n",
    "    - We also need a measure for how good different augmentation compare.\n",
    "    - I need a test data to compare different classifier models, but there are already just 20 patients and 20 control\n",
    "    - \n",
    "- TODO:\n",
    "    - Train a classifier with out augmenting the data. Therefore we need a train, validation and test set to select a good model! \n",
    "        - Problem: is 40 patients to few for a classifier to do well?\n",
    "    - Compare a classifier trained on GMM with 8 componenets vs 36 components (two basic ways to augment the data). To do so, we need a simple classifier that can take 20000*40 parameters as a single input. (perhaps a desision tree). We also need to split the data into train and test. \n",
    "    - Train a dicriminator that tries to distinguish between generated and original data. Use that to rate the quality of generated data. I.E. GAN\n",
    "\n",
    "- Question:\n",
    "    - Since there are only 20 patients, after the density is estimated, is it possible to oversample from this density? Too much bias or variance? How to we measure that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation:\n",
    "- generate mode data\n",
    "- want to compare how good the new sampling is by\n",
    "    1. comparing classifiers trained on non-augmented data vs augmented\n",
    "    2. we also need a measure for how good different augementation compare\n",
    "- a classifier that dicriminates between the generated and original data.\n",
    "\n",
    "- very good at the cell level, okey on patient\n",
    "- need a way to compare patients, density estimation\n",
    "- finetune\n",
    "- VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i)\n",
    "\n",
    "The average distance between two patients can be used to measure the closeness of a sampled patient to the original patients\n",
    "- need a way to measure distance between to patients. \n",
    "    - compare density?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
