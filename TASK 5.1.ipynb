{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5.2 Compare generated and original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:  The double-date metric\n",
    "- generated control cells/patients should be more similar to original control cells/patients than original diseased cells/patients **should be high**\n",
    "- generated diseased cells/patients should be more similar to original diseased cells/patients than original control data **should be high**\n",
    "- The difference between generated control and diseased cells/patients should be as close as possible to the difference between original control and diseased cells/patients. **should be low**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process old\n",
    "1. Train a generator on each group seperatly on the original data.\n",
    "2. Embedd the orignal data of each group seperately -> take each patients seperatly \n",
    "3. Generate patients -> embedd each patient using the same embedding space as the patients respective group.\n",
    "4. Get the KL-divergence between each pair of patient.\n",
    "    1. the kl-divergence is measured on the meshgrid spanning the union of each pair of patient cells.\n",
    "    2. Get two kernel density estimators, each trained on their respectiv patients embedding. Then use KL-divergence to compare the the estimations over the meshgrid.\n",
    "5. Use the double-date metric too compare generators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process new\n",
    "1. Train a generator on each group seperatly on the original data.\n",
    "2. Embedd the orignal data of each group  -> take each patients seperatly \n",
    "3. Generate patients -> embedd each patient using the same embedding space.\n",
    "4. Get the KL-divergence between each pair of patient.\n",
    "    1. the kl-divergence is measured on the meshgrid spanning the union of each pair of patient cells.\n",
    "    2. Get two kernel density estimators, each trained on their respectiv patients embedding. Then use KL-divergence to compare the the estimations over the meshgrid.\n",
    "5. Use the double-date metric too compare generators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critisim\n",
    "1. Factors that might affect the metric\n",
    "    1. The embedding algorthim. The properties of some algorithm used will transfer to the metric. **Embedding groups in different space, will make the difference already big**\n",
    "    2. The way KL-divergence is used. The span of the meshgrid will vary.\n",
    "    3. The kernel density estimator. Different parameters might give different results.\n",
    "    4. The generators themselves will vary with hyperparameters. (These are the models we to validate.)\n",
    "    5. The number of generated patients might affect metric. \n",
    "    6. The double-date metric might not be a good metric itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Train a generator on each group seperatly on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generated data \n",
    "# or load some generator \n",
    "# or train a generator - do this in another file\n",
    "def load_patients(file):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    file: csv with cells of patients.\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    df: Dataframe version of the csv file\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "\n",
    "def load_generator(file):\n",
    "    pass # TODO\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    pass # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Embedd each group seperately -> take each patients seperatly OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNE\n",
    "from openTSNE.callbacks import ErrorLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_embedd(df, embedder=None):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df: dataframe with cells of patients\n",
    "    embedder: umap embedding with existing embedded space.\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    embedder: umap embedder with existing embedded space\n",
    "    \n",
    "    embedded: embedding of df using embedder\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    group_embedding = dict()\n",
    "    \n",
    "    if(not embedder):\n",
    "        embedders = {\"control\": umap.UMAP(n_components=2, n_neighbors=10, random_state=0),\n",
    "                    \"diseased\": umap.UMAP(n_components=2, n_neighbors=10, random_state=0)}\n",
    "\n",
    "    groups = [\"control\", \"diseased\"]\n",
    "    for g in groups:\n",
    "        group = df.groupby(\"groub\").get_group(g)\n",
    "        group_cells = group[group.columns.difference([\"id\",\"group\"])]\n",
    "        group_embedding[g] = embedder.fit_transform(group_cells)\n",
    "    return up, group_embedding\n",
    "    \n",
    "    \n",
    "def tsne_embedd(df, embedders=None):  \n",
    "    \"\"\"\n",
    "    PARAMETRS\n",
    "    ---------\n",
    "    df: dataframe with cells of patients\n",
    "    embedders: OpenTSNE - TSNEEmbedding object, one for each group of patient\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    embedders: tsne embedders with existing embedded space, one for each group of patient\n",
    "    \n",
    "    embedded: embedding of df using embedder\n",
    "    \n",
    "    \"\"\"\n",
    "    group_embedding = dict()\n",
    "    groups = [\"control\", \"diseased\"]\n",
    "    if(not embedders):\n",
    "        embedders = {\"control\": TSNE(n_components=2, perplexity=30, \n",
    "                    learning_rate=20, n_iter=1000, \n",
    "                    random_state=0),\n",
    "                    \"diseased\": TSNE(n_components=2, perplexity=30, \n",
    "                    learning_rate=20, n_iter=1000, \n",
    "                    random_state=0)}\n",
    "        \n",
    "        for g in groups:\n",
    "            group = df.groupby(\"group\").get_group(g)\n",
    "            group_cells = group[group.columns.difference([\"id\",\"group\"])]\n",
    "            group_embedding[g] = embedders[g].fit(group_cells.values)\n",
    "    else:\n",
    "        for g in groups:\n",
    "            group = df.groupby(\"group\").get_group(g)\n",
    "            group_cells = group[group.columns.difference([\"id\",\"group\"])]\n",
    "            group_embedding[g] = embedders[g].transform(group_cells.values)\n",
    "            \n",
    "        \n",
    "    return embedders, group_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get the KL-divergence between each pair of patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kl_between_pairs(original, generated):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    original: a dictionary containing the embedded control and patient of the original patients\n",
    "    \n",
    "    generated: a dictonary containing the embedded control and patient of the generated patients\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    pairwise_kl: a list of matrices. each matrix contains a kl between two groups.\n",
    "    \n",
    "    \"\"\"\n",
    "    def KL(a,b):\n",
    "        a = np.asarray(a, dtype=np.float)\n",
    "        b = np.asarray(b, dtype=np.float)\n",
    "        a = np.exp(np.where(a!= float('-inf'), a, 0))\n",
    "        b = np.exp(np.where(b!= float('-inf'), b, 0))\n",
    "\n",
    "        cond = np.logical_and(b != float('-inf'), a!= float('-inf'), b != 0)\n",
    "    \n",
    "        return np.sum(np.where(cond, a * np.log(a / b), 0))\n",
    "    \n",
    "    def meshgrid(min_value = -15,max_value=15):\n",
    "        grid_margins = [np.linspace(min_value, max_value, 120)] * 2\n",
    "        grid = np.stack(np.meshgrid(*grid_margins), -1).reshape(-1, len(grid_margins))\n",
    "        return grid\n",
    "\n",
    "    def KL_between_two_patients(p1, p2, symmetric=True):\n",
    "        max_1 = np.max(p1)\n",
    "        min_1 = np.min(p1)\n",
    "        max_2 = np.max(p2)\n",
    "        min_2 = np.min(p2)\n",
    "        X = meshgrid(min_value = np.min([min_1, min_2])-1, max_value = np.max([max_1,max_2])+1 )\n",
    "\n",
    "        P_k_density_estimator = KernelDensity(kernel = \"linear\", bandwidth=1).fit(p1)\n",
    "        P_sample_score = P_k_density_estimator.score_samples(X)\n",
    "\n",
    "        Q_k_density_estimator = KernelDensity(kernel = \"linear\", bandwidth=1).fit(p2)\n",
    "        Q_sample_score = Q_k_density_estimator.score_samples(X)\n",
    "        kl_score = 0\n",
    "\n",
    "        if(symmetric):\n",
    "            kl_score = KL(P_sample_score, Q_sample_score) + KL(Q_sample_score, P_sample_score)\n",
    "        else:\n",
    "            kl_score = KL(P_sample_score, Q_sample_score)\n",
    "\n",
    "        return kl_score\n",
    "    \n",
    "    \n",
    "    \n",
    "    KL_sum_cc = np.empty((20,20))\n",
    "    KL_sum_dd = np.empty((20,20))\n",
    "    KL_sum_cd = np.empty((20,20))\n",
    "    KL_sum_dc = np.empty((20,20))\n",
    "    for i in range(20):\n",
    "        for j in range(20):# Get the KL divergence between each pair of sample and original patient\n",
    "            KL_sum_cc[i,j] = KL_between_two_patients(generated[\"control\"][i], original[\"control\"][j])\n",
    "            KL_sum_dd[i,j] = KL_between_two_patients(generated[\"diseased\"][i], original[\"diseased\"][j])\n",
    "            KL_sum_cd[i,j] = KL_between_two_patients(generated[\"diseased\"][i], original[\"control\"][j])\n",
    "            KL_sum_dc[i,j] = KL_between_two_patients(generated[\"control\"][i], original[\"diseased\"][j])\n",
    "\n",
    "    return [KL_sum_cc, KL_sum_dd, KL_sum_cd, KL_sum_dc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Double-date matric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualization of the pairwise KL-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(KL_sum_cc, KL_sum_dd, KL_sum_cd, KL_sum_dc):\n",
    "    ab = np.concatenate((KL_sum_cc,KL_sum_cd),axis=1)\n",
    "    cd = np.concatenate((KL_sum_dc,KL_sum_dd),axis=1)\n",
    "    abcd = np.concatenate((ab,cd),axis=0)\n",
    "    \n",
    "    plt.figure(fig_size=(16,16))\n",
    "    sns.set()\n",
    "    ax = sns.heatmap(abcd)\n",
    "    ax.set_xlabel(\"original c d\")\n",
    "    ax.set_ylabel(\"sampled d c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(data, title):\n",
    "    fig, ax = plt.subplots(1, len(response), sharex=True, sharey=True)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(18)\n",
    "    for i, r in enumerate(response):\n",
    "        sns.boxplot(data=data[i], ax=ax[i])\n",
    "        ax[i].set_title(r)\n",
    "    ax[0].set_ylabel('average KL divergence')\n",
    "    fig.subplots_adjust(wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 load original and generated data\n",
    "df_org = load_patients(\"original_patients.csv\") # TODO\n",
    "df_gen = load_patients(\"generated_patients.csv\") # TODO\n",
    "\n",
    "#2 Embedd data TODO: turn group_embeddings into dataframes\n",
    "tsne_org, group_embedding_tsne_org = embedd_tsne(df_org)\n",
    "tsne_gen, group_embedding_tsne_gen = embedd_tsne(df_gen, tsne_org)\n",
    "\n",
    "umap_org, group_embedding_umap_org = embedd_umap(df_org)\n",
    "umap_gen, group_embedding_umap_org= embedd_umap(df_gen, umap_org)\n",
    "\n",
    "#3 get kl_div\n",
    "\n",
    "\n",
    "\n",
    "title_8 = ['CC_8', 'CD_8', 'DC_8', 'DD_8']\n",
    "data_8 = [KL_sum_cc_8, KL_sum_cd_8, KL_sum_dc_8, KL_sum_dd_8]\n",
    "box_plot(data_8, title_8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
